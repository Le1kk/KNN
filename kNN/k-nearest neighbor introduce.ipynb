{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k近邻法(k-nearest neighbors)是由Cover和Hart于1968年提出的，它是懒惰学习(lazy learning)的著名代表。<br>它的工作机制比较简单：\n",
    "- 给定一个测试样本\n",
    "- 计算它到训练样本的距离\n",
    "- 取离测试样本最近的`k`个训练样本\n",
    "- “投票法”选出在这k个样本中出现最多的类别，就是预测的结果\n",
    "\n",
    "\n",
    "> 距离衡量的标准有很多，常见的有：欧氏距离、曼哈顿距离、余弦值、Lp距离(Lp范数)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什么意思呢？先来看这张图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2个类](img\\P1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们对应上面的流程来说\n",
    "- 1.给定了红色和蓝色的训练样本，绿色为测试样本\n",
    "- 2.计算绿色点到其他点的距离\n",
    "- 3.选取离绿点最近的k个点\n",
    "- 4.选取k个点中，同种颜色最多的类。例如：k=1时，k个点全是蓝色，那预测结果就是Class 1；k=3时，k个点中两个红色一个蓝色，那预测结果就是Class 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 举例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里用`欧氏距离`作为距离的衡量标准，用鸢尾花数据集举例说明。\n",
    "鸢尾花数据集有三个类别，每个类有150个样本，每个样本有4个特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先来回顾一下欧氏距离的定义(摘自维基百科)：<br>\n",
    "> 在欧几里得空间中，点 x = (x1,...,xn) 和 y = (y1,...,yn) 之间的欧氏距离为<br>\n",
    " $d(x,y):={\\sqrt  {(x_{1}-y_{1})^{2}+(x_{2}-y_{2})^{2}+\\cdots +(x_{n}-y_{n})^{2}}}={\\sqrt  {\\sum _{{i=1}}^{n}(x_{i}-y_{i})^{2}}}$<br>\n",
    " \n",
    "> 向量 ${\\displaystyle {\\vec {x}}}$的自然长度，即该点到原点的距离为<br>\n",
    " $\\|{\\vec  {x}}\\|_{2}={\\sqrt  {|x_{1}|^{2}+\\cdots +|x_{n}|^{2}}}$<br>\n",
    " 它是一个纯数值。在欧几里得度量下，两点之间线段最短。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在给出六个训练样本，分为三类，每个样本有4个特征，编号为7的`名称`是我们要预测的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|编号|花萼长度(cm)|花萼宽度(cm)|花瓣长度(cm)|花瓣宽度(cm)|名称|\n",
    "|----|----------|-----------|-----------|----------|----|\n",
    "|1|4.9|3.1|1.5|0.1|Iris setosa|\n",
    "|2|5.4|3.7|1.5|0.2|Iris setosa|\n",
    "|3|5.2|2.7|3.9|1.4|Iris versicolor|\n",
    "|4|5.0|2.0|3.5|1.0|Iris versicolor|\n",
    "|5|6.3|2.7|4.9|1.8|Iris virginica|\n",
    "|6|6.7|3.3|5.7|2.1|Iris virginica|\n",
    "|7|5.5|2.5|4.0|1.3|    ?    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照之前说的步骤，我们来计算测试样本到各个训练样本的距离。例如到第一个样本的距离$d_{1}=\\sqrt{(4.9 - 5.5)^2 + (3.1 - 2.5)^2 + (1.5 - 4.0)^2 + (0.1 - 1.3)^2} = 2.9$\n",
    "\n",
    "写一个函数来执行这个操作吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance to 1: 2.9\n",
      "Distance to 2: 2.98496231132\n",
      "Distance to 3: 0.387298334621\n",
      "Distance to 4: 0.916515138991\n",
      "Distance to 5: 1.31909059583\n",
      "Distance to 6: 2.36854385647\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def calc_distance(iA,iB):\n",
    "    temp = np.subtract(iA, iB)      # 对应元素相减\n",
    "    temp = np.power(temp, 2)        # 元素分别平方\n",
    "    distance = np.sqrt(temp.sum())  # 先求和再开方\n",
    "    return distance\n",
    "\n",
    "testSample = np.array([5.5, 2.5, 4.0, 1.3])\n",
    "print(\"Distance to 1:\", calc_distance(np.array([4.9, 3.1, 1.5, 0.1]), testSample))\n",
    "print(\"Distance to 2:\", calc_distance(np.array([5.4, 3.7, 1.5, 0.2]), testSample))\n",
    "print(\"Distance to 3:\", calc_distance(np.array([5.2, 2.7, 3.9, 1.4]), testSample))\n",
    "print(\"Distance to 4:\", calc_distance(np.array([5.0, 2.0, 3.5, 1.0]), testSample))\n",
    "print(\"Distance to 5:\", calc_distance(np.array([6.3, 2.7, 4.9, 1.8]), testSample))\n",
    "print(\"Distance to 6:\", calc_distance(np.array([6.7, 3.3, 5.7, 2.1]), testSample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们把k定为3，那么离测试样本最近3个依次是：\n",
    "\n",
    "|编号|名称|\n",
    "|----|---|\n",
    "|3|Iris versicolor|\n",
    "|4|Iris versicolor|\n",
    "|5|Iris virginica|\n",
    "\n",
    "显然测试样本属于`Iris versicolor`类的“票数”多一点，事实上它的确属于这个类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到这你可能已经意识到有点问题了，选择一个合适的k值的确可以减少模型受噪音的音响，但是当样本不平衡的时候呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![不平衡](img\\P2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们从直观上可以看出X和Y应该属于$\\omega_{1}$，但是对于Y来说，在k范围内，更多的点属于$\\omega_{2}$，这就造成了错误分类。<br>\n",
    "由于它属于懒惰学习，因此需要大量的空间来存储训练实例，在预测时它还需要与已知所有实例进行比较，这就造成了它的复杂度比较高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一个结论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在周志华编著的《机器学习》中证明了最近邻学习器的泛化错误率不超过贝叶斯最优分类器的错误率的两倍，在原书的226页，这里就不摘抄了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码实现KNN算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def load_data(path, rate = 0.8):\n",
    "    ''' Making dataSet\n",
    "    Args:\n",
    "        path: DataSet file path.\n",
    "        rate: TrainSet percentage.\n",
    "    Returns:\n",
    "        trainSet: Training set.\n",
    "        trainLabel: Training label.\n",
    "        testSet: Test set.\n",
    "        testLabel: Test label.\n",
    "    '''\n",
    "    data = pd.read_csv(path)\n",
    "    randIndex = random.sample(range(0, len(data)), len(data))\n",
    "    trainSet = data.loc[randIndex[:int(len(data) * rate)]]\n",
    "    testSet = data.loc[randIndex[int(len(data) * rate):]]\n",
    "    trainLabel = trainSet['name']\n",
    "    testLabel = testSet['name']\n",
    "    trainSet.drop('name', axis=1, inplace=True)\n",
    "    testSet.drop('name', axis=1, inplace=True)\n",
    "    return np.array(trainSet), np.array(trainLabel), np.array(testSet), np.array(testLabel)\n",
    "\n",
    "def euclideanDistance(instance1, instance2):\n",
    "    ''' Calculate two-point Euclidean distance\n",
    "    Args:\n",
    "        instance1: Numpy array type training set.\n",
    "        instance2: The element of test set.\n",
    "    Returns:\n",
    "        distance: The distance of instance2 to instance1, the type is list.\n",
    "    '''\n",
    "    distance = []\n",
    "    for instance in instance1:\n",
    "        temp = np.subtract(instance, instance2)\n",
    "        temp = np.power(temp, 2)\n",
    "        temp = temp.sum()\n",
    "        distance.append(np.sqrt(temp))\n",
    "    return distance\n",
    "\n",
    "def getNeighbors(distance, label, k):\n",
    "    ''' Calculate k-nearest element\n",
    "    Args:\n",
    "        distance: Return by euclideanDistance function.\n",
    "        label: Training label.\n",
    "        k: k-nearest\n",
    "    Returns:\n",
    "        neighbors: The k-nearest elements.\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    df['distance'] = distance\n",
    "    df['label'] = label\n",
    "    neighbors = df.sort_values(by='distance').reset_index()\n",
    "    return neighbors.loc[:k-1]\n",
    "\n",
    "def getResult(neighbors):\n",
    "    neighbors = neighbors['label'].value_counts()\n",
    "    neighbors = pd.Series(neighbors).sort_values(ascending=False).reset_index()\n",
    "    return neighbors['index'][0]\n",
    "\n",
    "def getAccuracy(testData, testLabel, trainSet, trainLabel):\n",
    "    ''' Calculate accuracy percentage.\n",
    "    Args:\n",
    "        testData: Numpy array of test set.\n",
    "        testLabel: Numpy array of test labels.\n",
    "        trainSet: Numpy array of train set.\n",
    "        trainLabel: Numpy array of train labels.\n",
    "    Returns:\n",
    "        score/len(trainLabel)\n",
    "    '''\n",
    "    score = 0\n",
    "    i = 0\n",
    "    for instance in testData:\n",
    "        distance = euclideanDistance(trainSet, instance)\n",
    "        neighbors = getNeighbors(distance, trainLabel, 5)\n",
    "        result = getResult(neighbors)\n",
    "        if result == testLabel[i]:\n",
    "            score += 1\n",
    "        i += 1\n",
    "    return score/len(trainLabel)\n",
    "\n",
    "if  __name__ == \"__main__\":\n",
    "    trainData, trainLabel, testData, testLabel = load_data(\"irisdata.txt\", 0.67)\n",
    "    print(getAccuracy(np.array(testData), np.array(testLabel), np.array(trainData), np.array(trainLabel)))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码写的比较糟糕，知道怎么个流程就好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
